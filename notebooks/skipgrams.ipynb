{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from nltk.util import skipgrams, ngrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'a', 'test', 'sentence', 'how', 'cool', 'is', 'that', 'mr.', 'joe']\n",
      "1.93 µs ± 11.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "test_sent = 'I am a test sentence.  How cool is that, Mr. Joe?'\n",
    "test_sent = word_tokenize(test_sent.lower())\n",
    "test_sent = list(filter(lambda c: c not in string.punctuation, test_sent))\n",
    "print(test_sent)\n",
    "%timeit list(filter(lambda c: c not in string.punctuation, test_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 ns ± 2.15 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 'am'),\n",
       " ('am', 'a'),\n",
       " ('a', 'test'),\n",
       " ('test', 'sentence'),\n",
       " ('sentence', 'how'),\n",
       " ('how', 'cool'),\n",
       " ('cool', 'is'),\n",
       " ('is', 'that'),\n",
       " ('that', 'mr.'),\n",
       " ('mr.', 'joe')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit ngrams(test_sent, 2)\n",
    "list(ngrams(test_sent, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 ns ± 1.64 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 'am', 'a'),\n",
       " ('i', 'am', 'test'),\n",
       " ('i', 'am', 'sentence'),\n",
       " ('i', 'am', 'how'),\n",
       " ('i', 'a', 'test'),\n",
       " ('i', 'a', 'sentence'),\n",
       " ('i', 'a', 'how'),\n",
       " ('i', 'test', 'sentence'),\n",
       " ('i', 'test', 'how'),\n",
       " ('i', 'sentence', 'how'),\n",
       " ('am', 'a', 'test'),\n",
       " ('am', 'a', 'sentence'),\n",
       " ('am', 'a', 'how'),\n",
       " ('am', 'a', 'cool'),\n",
       " ('am', 'test', 'sentence'),\n",
       " ('am', 'test', 'how'),\n",
       " ('am', 'test', 'cool'),\n",
       " ('am', 'sentence', 'how'),\n",
       " ('am', 'sentence', 'cool'),\n",
       " ('am', 'how', 'cool'),\n",
       " ('a', 'test', 'sentence'),\n",
       " ('a', 'test', 'how'),\n",
       " ('a', 'test', 'cool'),\n",
       " ('a', 'test', 'is'),\n",
       " ('a', 'sentence', 'how'),\n",
       " ('a', 'sentence', 'cool'),\n",
       " ('a', 'sentence', 'is'),\n",
       " ('a', 'how', 'cool'),\n",
       " ('a', 'how', 'is'),\n",
       " ('a', 'cool', 'is'),\n",
       " ('test', 'sentence', 'how'),\n",
       " ('test', 'sentence', 'cool'),\n",
       " ('test', 'sentence', 'is'),\n",
       " ('test', 'sentence', 'that'),\n",
       " ('test', 'how', 'cool'),\n",
       " ('test', 'how', 'is'),\n",
       " ('test', 'how', 'that'),\n",
       " ('test', 'cool', 'is'),\n",
       " ('test', 'cool', 'that'),\n",
       " ('test', 'is', 'that'),\n",
       " ('sentence', 'how', 'cool'),\n",
       " ('sentence', 'how', 'is'),\n",
       " ('sentence', 'how', 'that'),\n",
       " ('sentence', 'how', 'mr.'),\n",
       " ('sentence', 'cool', 'is'),\n",
       " ('sentence', 'cool', 'that'),\n",
       " ('sentence', 'cool', 'mr.'),\n",
       " ('sentence', 'is', 'that'),\n",
       " ('sentence', 'is', 'mr.'),\n",
       " ('sentence', 'that', 'mr.'),\n",
       " ('how', 'cool', 'is'),\n",
       " ('how', 'cool', 'that'),\n",
       " ('how', 'cool', 'mr.'),\n",
       " ('how', 'cool', 'joe'),\n",
       " ('how', 'is', 'that'),\n",
       " ('how', 'is', 'mr.'),\n",
       " ('how', 'is', 'joe'),\n",
       " ('how', 'that', 'mr.'),\n",
       " ('how', 'that', 'joe'),\n",
       " ('how', 'mr.', 'joe'),\n",
       " ('cool', 'is', 'that'),\n",
       " ('cool', 'is', 'mr.'),\n",
       " ('cool', 'is', 'joe'),\n",
       " ('cool', 'that', 'mr.'),\n",
       " ('cool', 'that', 'joe'),\n",
       " ('cool', 'mr.', 'joe'),\n",
       " ('is', 'that', 'mr.'),\n",
       " ('is', 'that', 'joe'),\n",
       " ('is', 'mr.', 'joe'),\n",
       " ('that', 'mr.', 'joe')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit ngrams(test_sent, 3, 3)\n",
    "list(skipgrams(test_sent, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skipgram_analyzer(s, skipgram_list=[(1, 0)]):\n",
    "    '''\n",
    "    An analyzer that splits a string s into a list of (n, k) skipgrams\n",
    "    for each (n, k) pair in the skipgrams list.\n",
    "    '''\n",
    "    s = word_tokenize(s.lower())\n",
    "    s = list(filter(lambda c: c not in string.punctuation, s))\n",
    "\n",
    "    ret = []\n",
    "    for n, k in skipgram_list:\n",
    "        if k == 0:\n",
    "            ret += list(ngrams(s, n))\n",
    "        else:\n",
    "            ret += skipgrams(s, n, k)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "[('i',), ('am',), ('a',), ('test',), ('sentence',), ('how',), ('cool',), ('is',), ('that',), ('mr.',), ('joe',), ('i', 'am'), ('i', 'a'), ('i', 'test'), ('i', 'sentence'), ('am', 'a'), ('am', 'test'), ('am', 'sentence'), ('am', 'how'), ('a', 'test'), ('a', 'sentence'), ('a', 'how'), ('a', 'cool'), ('test', 'sentence'), ('test', 'how'), ('test', 'cool'), ('test', 'is'), ('sentence', 'how'), ('sentence', 'cool'), ('sentence', 'is'), ('sentence', 'that'), ('how', 'cool'), ('how', 'is'), ('how', 'that'), ('how', 'mr.'), ('cool', 'is'), ('cool', 'that'), ('cool', 'mr.'), ('cool', 'joe'), ('is', 'that'), ('is', 'mr.'), ('is', 'joe'), ('that', 'mr.'), ('that', 'joe'), ('mr.', 'joe'), ('i', 'am', 'a'), ('i', 'am', 'test'), ('i', 'am', 'sentence'), ('i', 'a', 'test'), ('i', 'a', 'sentence'), ('i', 'test', 'sentence'), ('am', 'a', 'test'), ('am', 'a', 'sentence'), ('am', 'a', 'how'), ('am', 'test', 'sentence'), ('am', 'test', 'how'), ('am', 'sentence', 'how'), ('a', 'test', 'sentence'), ('a', 'test', 'how'), ('a', 'test', 'cool'), ('a', 'sentence', 'how'), ('a', 'sentence', 'cool'), ('a', 'how', 'cool'), ('test', 'sentence', 'how'), ('test', 'sentence', 'cool'), ('test', 'sentence', 'is'), ('test', 'how', 'cool'), ('test', 'how', 'is'), ('test', 'cool', 'is'), ('sentence', 'how', 'cool'), ('sentence', 'how', 'is'), ('sentence', 'how', 'that'), ('sentence', 'cool', 'is'), ('sentence', 'cool', 'that'), ('sentence', 'is', 'that'), ('how', 'cool', 'is'), ('how', 'cool', 'that'), ('how', 'cool', 'mr.'), ('how', 'is', 'that'), ('how', 'is', 'mr.'), ('how', 'that', 'mr.'), ('cool', 'is', 'that'), ('cool', 'is', 'mr.'), ('cool', 'is', 'joe'), ('cool', 'that', 'mr.'), ('cool', 'that', 'joe'), ('cool', 'mr.', 'joe'), ('is', 'that', 'mr.'), ('is', 'that', 'joe'), ('is', 'mr.', 'joe'), ('that', 'mr.', 'joe')]\n"
     ]
    }
   ],
   "source": [
    "test_sent = 'I am a test sentence.  How cool is that, Mr. Joe?'\n",
    "feat = skipgram_analyzer(test_sent, skipgram_list=[(1, 0), (2, 3), (3, 2)])\n",
    "print(len(feat))\n",
    "print(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = TfidfVectorizer(stop_words='english', max_features=10000, \n",
    "                    analyzer = lambda s: skipgram_analyzer(s, skipgram_list=[(1, 0), (2, 3), (3, 2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 124)\n"
     ]
    }
   ],
   "source": [
    "T = t.fit_transform(['I am a test sentence.  How cool is that, Mr. Joe?',\n",
    "                     'Greetings, human.  I am another test sentence.']).toarray()\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('a',): 0,\n",
       " ('a', 'cool'): 1,\n",
       " ('a', 'how'): 2,\n",
       " ('a', 'how', 'cool'): 3,\n",
       " ('a', 'sentence'): 4,\n",
       " ('a', 'sentence', 'cool'): 5,\n",
       " ('a', 'sentence', 'how'): 6,\n",
       " ('a', 'test'): 7,\n",
       " ('a', 'test', 'cool'): 8,\n",
       " ('a', 'test', 'how'): 9,\n",
       " ('a', 'test', 'sentence'): 10,\n",
       " ('am',): 11,\n",
       " ('am', 'a'): 12,\n",
       " ('am', 'a', 'how'): 13,\n",
       " ('am', 'a', 'sentence'): 14,\n",
       " ('am', 'a', 'test'): 15,\n",
       " ('am', 'another'): 16,\n",
       " ('am', 'another', 'sentence'): 17,\n",
       " ('am', 'another', 'test'): 18,\n",
       " ('am', 'how'): 19,\n",
       " ('am', 'sentence'): 20,\n",
       " ('am', 'sentence', 'how'): 21,\n",
       " ('am', 'test'): 22,\n",
       " ('am', 'test', 'how'): 23,\n",
       " ('am', 'test', 'sentence'): 24,\n",
       " ('another',): 25,\n",
       " ('another', 'sentence'): 26,\n",
       " ('another', 'test'): 27,\n",
       " ('another', 'test', 'sentence'): 28,\n",
       " ('cool',): 29,\n",
       " ('cool', 'is'): 30,\n",
       " ('cool', 'is', 'joe'): 31,\n",
       " ('cool', 'is', 'mr.'): 32,\n",
       " ('cool', 'is', 'that'): 33,\n",
       " ('cool', 'joe'): 34,\n",
       " ('cool', 'mr.'): 35,\n",
       " ('cool', 'mr.', 'joe'): 36,\n",
       " ('cool', 'that'): 37,\n",
       " ('cool', 'that', 'joe'): 38,\n",
       " ('cool', 'that', 'mr.'): 39,\n",
       " ('greetings',): 40,\n",
       " ('greetings', 'am'): 41,\n",
       " ('greetings', 'am', 'another'): 42,\n",
       " ('greetings', 'another'): 43,\n",
       " ('greetings', 'human'): 44,\n",
       " ('greetings', 'human', 'am'): 45,\n",
       " ('greetings', 'human', 'another'): 46,\n",
       " ('greetings', 'human', 'i'): 47,\n",
       " ('greetings', 'i'): 48,\n",
       " ('greetings', 'i', 'am'): 49,\n",
       " ('greetings', 'i', 'another'): 50,\n",
       " ('how',): 51,\n",
       " ('how', 'cool'): 52,\n",
       " ('how', 'cool', 'is'): 53,\n",
       " ('how', 'cool', 'mr.'): 54,\n",
       " ('how', 'cool', 'that'): 55,\n",
       " ('how', 'is'): 56,\n",
       " ('how', 'is', 'mr.'): 57,\n",
       " ('how', 'is', 'that'): 58,\n",
       " ('how', 'mr.'): 59,\n",
       " ('how', 'that'): 60,\n",
       " ('how', 'that', 'mr.'): 61,\n",
       " ('human',): 62,\n",
       " ('human', 'am'): 63,\n",
       " ('human', 'am', 'another'): 64,\n",
       " ('human', 'am', 'test'): 65,\n",
       " ('human', 'another'): 66,\n",
       " ('human', 'another', 'test'): 67,\n",
       " ('human', 'i'): 68,\n",
       " ('human', 'i', 'am'): 69,\n",
       " ('human', 'i', 'another'): 70,\n",
       " ('human', 'i', 'test'): 71,\n",
       " ('human', 'test'): 72,\n",
       " ('i',): 73,\n",
       " ('i', 'a'): 74,\n",
       " ('i', 'a', 'sentence'): 75,\n",
       " ('i', 'a', 'test'): 76,\n",
       " ('i', 'am'): 77,\n",
       " ('i', 'am', 'a'): 78,\n",
       " ('i', 'am', 'another'): 79,\n",
       " ('i', 'am', 'sentence'): 80,\n",
       " ('i', 'am', 'test'): 81,\n",
       " ('i', 'another'): 82,\n",
       " ('i', 'another', 'sentence'): 83,\n",
       " ('i', 'another', 'test'): 84,\n",
       " ('i', 'sentence'): 85,\n",
       " ('i', 'test'): 86,\n",
       " ('i', 'test', 'sentence'): 87,\n",
       " ('is',): 88,\n",
       " ('is', 'joe'): 89,\n",
       " ('is', 'mr.'): 90,\n",
       " ('is', 'mr.', 'joe'): 91,\n",
       " ('is', 'that'): 92,\n",
       " ('is', 'that', 'joe'): 93,\n",
       " ('is', 'that', 'mr.'): 94,\n",
       " ('joe',): 95,\n",
       " ('mr.',): 96,\n",
       " ('mr.', 'joe'): 97,\n",
       " ('sentence',): 98,\n",
       " ('sentence', 'cool'): 99,\n",
       " ('sentence', 'cool', 'is'): 100,\n",
       " ('sentence', 'cool', 'that'): 101,\n",
       " ('sentence', 'how'): 102,\n",
       " ('sentence', 'how', 'cool'): 103,\n",
       " ('sentence', 'how', 'is'): 104,\n",
       " ('sentence', 'how', 'that'): 105,\n",
       " ('sentence', 'is'): 106,\n",
       " ('sentence', 'is', 'that'): 107,\n",
       " ('sentence', 'that'): 108,\n",
       " ('test',): 109,\n",
       " ('test', 'cool'): 110,\n",
       " ('test', 'cool', 'is'): 111,\n",
       " ('test', 'how'): 112,\n",
       " ('test', 'how', 'cool'): 113,\n",
       " ('test', 'how', 'is'): 114,\n",
       " ('test', 'is'): 115,\n",
       " ('test', 'sentence'): 116,\n",
       " ('test', 'sentence', 'cool'): 117,\n",
       " ('test', 'sentence', 'how'): 118,\n",
       " ('test', 'sentence', 'is'): 119,\n",
       " ('that',): 120,\n",
       " ('that', 'joe'): 121,\n",
       " ('that', 'mr.'): 122,\n",
       " ('that', 'mr.', 'joe'): 123}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.74026997e-05,   1.05356462e+00],\n",
       "       [  8.81770694e-01,   0.00000000e+00]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = nmf.fit_transform(T)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.dump?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
